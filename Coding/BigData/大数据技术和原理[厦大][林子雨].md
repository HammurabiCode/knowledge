# 大数据简介
## 大数据时代
### 三次信息化浪潮

* 个人电脑：信息处理
* 互联网：信息传输
* 大数据+云计算+物联网：信息爆炸

### 大数据的技术基础

* 存储技术发展
* CPU处理能力提升
* 网络带宽提升

### 数据产生方式的变革：感知式，物联网

### 大数据发展历程

## 大数据定义：4V

* 量大：大数据摩尔定理-每两年翻一番。
* 类型多：大部分是非结构化数据
* 处理速度快m
* 价值密度低

## 影响
### Jim Gray:科学研究的第四种范式

实验->理论->计算->数据

### 《大数据时代》：传统思维方式的颠覆

* 全样而非抽样
* 效率而非精确
* 相关而非因果

## 大数据应用

## 大数据关键技术

* 分布式存储：分布式文件系统、分布式数据库
* 分布式处理：MapReduce

## 大数据计算模式

<table>
<tr>
    <td>计算模式</td>
    <td>解决问题</td>
    <td>代表产品</td>
</tr>
<tr>
    <td>批处理计算</td>
    <td>大规模数据的批量处理</td>
    <td>MapReduce, Spark</td>
</tr>
<tr>
    <td>批处理计算</td>
    <td>大规模数据的批量处理</td>
    <td>MapReduce, Spark</td>
</tr>
<tr>
    <td>流计算</td>
    <td>针对流数据的实时计算</td>
    <td>Storm, S4, Flume, Streams, Puma, DStream, Super Mario, 银河流数据处理平台</td>
</tr>
<tr>
    <td>图计算</td>
    <td>针对大规模图结构数据处理（社交网络、地理）</td>
    <td>Pregel, GraphX, Giraph, Power Graph, Hama, GoldenOrb</td>
</tr>
<tr>
    <td>查询分析计算</td>
    <td>大规模数据的存储管理和查询分析</td>
    <td>Dremel, Hive, Cassandra, Impala</td>
</tr>
</table>


## 大数据产业

## 大数据、云计算、物联网之间的关系

### 云计算的关键技术：分布式存储和分布式处理

* 多租户、虚拟化
* 公有云、混合云、私有云
* IaaS、PaaS、SaaS

### 物联网：识别感知、网络通信

###关系：

* 大数据是云计算的重要应用，用武之地；处理物联网搜集来的海量数据，将其转换为有价值的信息和知识。
* 云计算为大数据提供技术基础；存储处理物联网提供的海量数据。
* 物联网为云计算和大数据搜集数据。


# 大数据处理架构Hadoop

## 概述
### 简介

* Apache基金会的项目
* Java开发
* 核心构件：HDFS, MapReduce

### 简史： 2008年 排序1TB209秒 一战成名

### 特性

* 高可靠性
* 高效
* 易于扩展
* 容错
* 成本低
* 基于Linux
* 支持多种编程语言：Java, C/C++, Python

### 应用现状
<table>
    <tr>
        <td>数据分析（离线）</td>
        <td>实时查询</td>
        <td>数据挖掘</td>
    </tr>
    <tr align="center">
        <td>Hive/Pig</td>
        <td>Solr/Redis</td>
        <td rowspan="2">Mahout</td>
    </tr>
    <tr align="center">
        <td>MapReduce</td>
        <td>HBase</td>
    </tr>
    <tr align="center">
        <td colspan="3">HDFS</td>
    </tr>
</table>

### 版本
<table>
    <tr>
        <td>第一代</td>
        <td colspan="2">第二代</td>
    </tr>
    <tr>
        <td>0.20.x, 0.21.x, 0.22.x</td>
        <td colspan="2">0.23.x, 2.x</td>
    </tr>
    <tr>
        <td rowspan="2">MapReduce</td>
        <td>MapReduce</td>
        <td>Others: Spark,Strom...</td>
    </tr>
    <tr>
        <td colspan="2">YARN</td>
    </tr>
    <tr>
        <td>HDFS</td>
        <td colspan="2">HDFS</td>
    </tr>
</table>

Hadoop 2.0在架构上做的改进：
1. HDFS中，使用Name Node Federation, HA
2. 在HDFS之上新添加一层YARN专门负责资源管理，MapReduce不再处理资源管理，而专门进行数据处理
3. MapReduce运行与YARN之上，其他一些计算框架同样可以运行与YARN之上
4. YARN: Yet Another Resource Nagotiator

Hadoop的各种发行版：
- Apache Hadoop
- Cloudera：CDH, Cloudera Distribution Hadoop
- Hortonworks Hadoop
- MapR
- 星环


## Hadoop项目架构

<table>
    <tr>
        <td colspan="9">Ambari</td>
    </tr>
    <tr>
        <td rowspan="5">Zookeeper</td>
        <td rowspan="4">HBase</td>
        <td colspan="7">Oozie</td>
    </tr>
    <tr>
        <td colspan="1">Hive</td>
        <td colspan="1">Pig</td>
        <td colspan="1">Hive2</td>
        <td colspan="1">Pig2</td>
        <td colspan="1">Shark</td>
        <td colspan="2">...</td>
    </tr>
    <tr>
        <td colspan="2">MapReduce</td>
        <td colspan="2">TeZ</td>
        <td colspan="1">Spark</td>
        <td colspan="1">...</td>
        <td >Sqoop</td>
    </tr>
    <tr>
        <td colspan="6">YARN</td>
        <td rowspan="2">Flume</td>
    </tr>
    <tr>
        <td colspan="7">HDFS</td>
    </tr>
</table>

<table>
    <tr>
        <td>HDFS</td>
        <td>分布式文件系统</td>
    </tr>
    <tr>
        <td>YARN</td>
        <td>分布式计算框架</td>
    </tr>
    <tr>
        <td>MapReduce</td>
        <td>离线计算、批处理</td>
    </tr>
    <tr>
        <td>TeZ</td>
        <td>DAG计算，将任务分解为有向图，以提高效率</td>
    </tr>
    <tr>
        <td>Spark</td>
        <td>内存计算，比MapReduce更快<td>
    </tr>
    <tr>
        <td>Hive</td>
        <td><td>
    </tr>
    <tr>
        <td>Pig</td>
        <td><td>
    </tr>
</table>


# HDFS
## 简介
### 计算机集群结构

### 分布式文件系统的结构：主从结构


## HDFS简介
### 目标
    1. 兼容廉价硬件
    2. 流数据读写
    3. 大数据集
    4. 简单的文件模型
    5. 跨平台兼容性

### 缺陷
    1. 延时高
    2. 处理大量小文件时低效
    3. 不支持多用户
    4. 不能任意修改文件，只能追加


## 相关概念
### 块：一般默认64MB，减少寻址开销
- 支持大文件
- 简化系统设计
- 适合备份

### 名称节点和数据节点
<table>
    <tr>
        <td>NameNode</td>
        <td>文件元数据：fsimage, EditLog, 文件名、命名空间、文件与block的关系</td>
        <td>存于内存</td>
        <td>保存文件与block的关系</td>
    </tr>
    <tr>
        <td>DataNode</td>
        <td>文件内容</td>
        <td>磁盘</td>
        <td>block和本地文件之间的关系</td>
    </tr>
</table>

- fsimage：维护文件系统树结构，所有文件和文件夹的元数据
    元数据包括：文件的复制等级、修改和访问时间、访问权限、块个数、各个块的ID。
- EditLog：记录创建、删除、重命名等操作
- 名称节点启动：从磁盘加载fsimage，执行EditLog中的操作，创建一个新的fsimage和一个空的EditLog。在运行过程中，操作都保存到EditLog中。
- EditLog过大，通过SecondaryNameNode将EditLog的操作合并到fsimage中去，然后清空EditLog。先GET fsimage和EditLog，合并，POST fsimage。

## HDFS体系结构

### HDFS体系结构概述
- 名称节点：负责管理命名空间，处理客户端的数据访问
- 数据节点：完成具体的文件读写操作

### 通信协议
客户端和名称节点使用：客户端协议
名称节点和数据节点使用：数据节点协议
客户端和数据节点通过RPC来实现。

### 客户端
Java API， Shell命令

### 局限
1. 命名空间限制：名称节点的数据保存在内存中，受限于机器的内存
2. 性能瓶颈：名称节点的瓶颈
3. 隔离：只有一个命名空间
4. 集群可用性：单个名称节点

## 存储原理
### 冗余数据存储
可设置备份的个数
- 加快数据传输
- 查错
- 可靠

### 数据存取策略
数据存放策略
- 第一个副本：在上传的节点上，如果是外部提交，选择一个空间足够、CPU空闲的节点
- 第二个副本：在第一个副本的不同机架上
- 第三个副本：与第一副本同一机架的不同节点
- 更多副本：随机
读取：选择同一个机架的

### 数据错误和恢复
- 名称节点：第二名称节点做为冷备份
- 数据节点：向名称节点发送心跳数据；如果宕机导致副本数量小于冗余因子，则创建新的副本。
- 数据出错：用校验码检测，读取时先检查，出错则另外找副本；名称节点则复制创建新的副本。

## 文件读写过程
### Java API常用类
    - FileSystem <- DistributedFileSystem
    - FSDataInputStream <- DFSInputStream
### 读文件
    1. 设置环境变量Configuration：读取文件（hdfs-site.xml, core-site.xml）或代码中该设置。
        Configuration conf = new Configuration();

    2. 根据Configuration，获取文件系统FileSystem:
        FileSystem fs = FileSystem.get(conf);
    3. 打开文件，获取输入流DFSInputStream:
        FSDataInputStream in = fs.open(new Path(...));
    4. DFSInputStream对象访问NameNode，找到文件对应的是哪个块，并在所有副本中，找到离客户端最近的一个副本。
    5. 从最近的副本所在的DataNode中读取数据。
    6. 如果数据发生变化，则再执行上一步继续询问。
    7. 关闭文件

### 写文件
    1. 
    2. 
    3. fs创建文件，访问NameNode，并获取DFSOutputStream对象。
    4. DFSOutputStream对象将DataNode，并流水线复制，复制成功后，流水线反向发送确认包。
    5. 关闭文件
    6. 通知NameNode写入完成。

## [编程实践](http://dblab.xmu.edu.cn/blog/290-2)
### Shell
    - hadoop fs
    - hadoop dfs
    - hdfs dfs

    * -cat
    * -copyFromLocal
    * -copyToLocal
    * -ls

### Java API
    导入JAR包


# HBase

# Spark
## Spark 概述
### Spark 简介
    - UCBerkeley AMP 实验室
    - 基于内存的
    - 2013加入Apache孵化器项目，现已成为三大分布式计算系统开源项目之一(Hadoop, Storm, Spark)
    - 2014年打破Hadoop的基准排序纪录：
        * Spark: 206节点/23min/100TB
        * Hadoop: 2000节点/72min/100TB
    - Spark 特点
        * 运行速度快：DAG，支持循环数据流，内存
        * 易用：Scala、Java、Python、R、Spark Shell
        * 通用：完整强大的技术栈，Spark Core, Spark MLlib, Spark Streaming.
        * 运行模式多样：独立集群部署；Hadoop中，YARN；云Amazon EC2；可访问HDFS, Hive, HBase, Cassandra
    - Google 趋势

### Scala 简介
    - Spark由Scala开发
    - 多范式编程语言：函数式编程(Lisp, Haskell)，面向对象
    - 运行在Java平台上
    - 特点：
        * 支持函数式编程和分布式系统
        * 语法简洁
        * 兼容Java，能融入Hadoop
        * 支持交互式解释器REPL(Read-Eval_Print Loop)

### Spark VS Hadoop
    - Hadoop的一些缺陷
        * 表达能力有限 - 限于Map 和 Reduce
        * 磁盘开销太大 - 输出都放入磁盘，应对迭代乏力
        * 延迟高 - 任务衔接；IO；同步等待（应对多阶段的计算任务乏力）
    - Spark的优势
        * 包含但是不局限于MapReduce，支持多种数据集操作类型，更加灵活
        * 内存计算，效率高，省去IO
        * DAG调度

## Spark 生态系统
    企业中大数据处理的三种应用场景

<table>
    <tr>
        <td>应用场景</td>
        <td>时间跨度</td>
        <td>Spark之外</td>
        <td>Spark</td>
    </tr>
    <tr>
        <td>复杂的批处理</td>
        <td>数十分钟到数小时</td>
        <td>MapReduce, Hive</td>
        <td>Spark</td>
    </tr>
    <tr>
        <td>基于历史数据的交互式查询</td>
        <td>数十秒到几分钟</td>
        <td>Impala, Dremel, Drill</td>
        <td>Spark SQL</td>
    </tr>
    <tr>
        <td>基于实时数据流的数据处理</td>
        <td>数百毫秒到数秒</td>
        <td>Storm(Twitter), S4(Yahoo)</td>
        <td>Spark Streaming</td>
    </tr>
    <tr>
        <td>基于历史数据的数据挖掘</td>
        <td> - </td>
        <td>Mahout</td>
        <td>MLlib</td>
    </tr>
    <tr>
        <td>图计算</td>
        <td> - </td>
        <td>Pregel, Hama</td>
        <td>GraphX</td>
    </tr>
</table>

    问题：
        * 数据之间的转换
        * 不同的维护开发团队
        * 难以进行统一的资源调度

    DBAS - Berkeley Data Analytics Stack: 伯克利数据分析软件栈

<table>
    <tr align="center">
        <td rowspan="2">Access and Interface</td>
        <td rowspan="2">访问接口</td>
        <td rowspan="2">Spark Streaming</td>
        <td>BlinkDB</td>
        <td rowspan="2">GraphX</td>
        <td>MLBase</td>
    </tr>
    <tr align="center">
        <td>Spark SQL</td>
        <td>MLlib</td>
    </tr>
    <tr align="center">
        <td>Processing Engine</td>
        <td>处理引擎</td>
        <td colspan="4">Spark Core</td>
    </tr>
    <tr align="center">
        <td>Storage</td>
        <td>存储</td>
        <td colspan="4">HDFS, S4</td>
    </tr>
    <tr align="center">
        <td>Resouce Virtualization</td>
        <td>资源抽象</td>
        <td colspan="2">Mesos</td>
        <td colspan="2">YARN</td>
    </tr>
</table>
<table>
    <tr align="center">
        <td>Tachyon</td>
        <td>分布式内存文件系统</td>
    </tr>
    <tr align="center">
        <td>Spark Core</td>
        <td></td>
    </tr>
    <tr align="center">
        <td>Spark Streaming</td>
        <td>流计算</td>
    </tr>
    <tr align="center">
        <td>Spark SQL</td>
        <td>交互式SQL查询</td>
    </tr>
    <tr align="center">
        <td>GraphX</td>
        <td>图计算</td>
    </tr>
    <tr align="center">
        <td>MLlib MLBase</td>
        <td>机器学习</td>
    </tr>
</table>


## Spark 运行架构
### 基本概念

 1. RDD: 弹性分布式数据集，分布式内存的抽象概念，提供高度受限的共享内存模型。将数据从磁盘读入RDD，RDD有多个分区，分区可以在不同节点上运行。
 2. DAG：有向无环图，反映RDD的依赖关系
 3. Executor: 运行具体Task的进程
 4. Application
 5. Task: 
 6. Job: 包含多个RDD及作用在RDD上的操作
 7. Stage: 即TaskSet，无Shuffle依赖关系
 8. WorkNode

### 架构设计

 - Cluster Manager: 资源管理器，自带的或YARN或Mesos。
 - WorkNode: 节点，用于执行任务。
 - Driver: 生成DAG，拆解，分配到WorkNode。
 - Executor: 执行进程，多线程。

优点：

* Executor多线程的，Hadoop是用进程。
* Executor中有一个BlockManager存储模块，将内存和磁盘统一管理，减少磁盘IO开销。


### Spark运行流程

 1. Driver构建起基本的运行环境，即SparkContext，负责资源申请、任务分配和监控。
 2. Cluster Manager为Executor分配资源，并启动Executor。
 3. SparkContext根据RDD的依赖关系，构建DAG，并将DAG提交给DAGScheduler，得到Stage，再调教给TaskScheduler，接到Executor申请后， 发放给Executor，同时发送代码。
 4. 运行结束后，Executor->TaskScheduler->DAGScheduler，释放资源。

 特点：

  * 每个Application有专属的Executor
  * 与资源管理器无关，只要能够获取Executor，并与之通信即可
  * 数据本地性：计算向数据靠拢
  * 推测执行：数据所在节点上忙时，推测迁移和等待的代价


### Spark运行原理

 1. 设计背景

  * 迭代计算（机器学习、图计算）和交互式数据挖掘工具：重用中间结果。Hadoop MapReduce中间结果写磁盘：复制、IO、序列化。
  * RDD解决中间结果存储的问题：抽象的数据结构，用“转换”来表达应用逻辑，实现管道化，避免中间数据存储。

 2. RDD概念

  * 一个分布式对象的集合，只读的分区记录集合。
  * 只读，高度受限，在转换操作中修改数据并保存到新的RDD中去。
  * 转换操作：Action, transformation两种类型。
  * 转换操作比较简单，但可以表达很多编程模型，如MapReduce, SQL, Pregel。
  
  典型的执行过程

   1. 读入数据，创建RDD，分区。
   2. 经过一系列transformation，每次transformation得到产生新的RDD，构成DAG。
   3. 最后一个RDD上进行action，得到结果。

   优点：管道化（避免中间结果存储）、每次操作简单（便于开发维护）、惰性调用、避免同步等待  

## Spark SQL
## Spark 部署和应用方式